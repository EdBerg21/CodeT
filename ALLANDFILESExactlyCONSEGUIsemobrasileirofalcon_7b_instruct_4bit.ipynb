{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76fa23b279164d2280e4667ed892ddf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbabc14946044ed4baa30c26018ca68c",
              "IPY_MODEL_19e4c8b42737471f8f3a13c665fa60f6",
              "IPY_MODEL_9144f7ae0ca44d5d88ec7bb238ad2eec"
            ],
            "layout": "IPY_MODEL_b6a16c9457cc4484b9f13ee335f681e8"
          }
        },
        "dbabc14946044ed4baa30c26018ca68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9594b6e7cac641f6ac6c44389c4fd5d2",
            "placeholder": "​",
            "style": "IPY_MODEL_8c4b7e971c574177b6e4e9c9c8d49dd9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "19e4c8b42737471f8f3a13c665fa60f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c924de601fc4c148bf966991879c8f8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22fb71dd266748eaa8310f8227d6fd36",
            "value": 2
          }
        },
        "9144f7ae0ca44d5d88ec7bb238ad2eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83d4f606cfb142a1b11c27be139c56e3",
            "placeholder": "​",
            "style": "IPY_MODEL_c4c8e5175fc04104a263ddffb051a7b6",
            "value": " 2/2 [01:18&lt;00:00, 36.26s/it]"
          }
        },
        "b6a16c9457cc4484b9f13ee335f681e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9594b6e7cac641f6ac6c44389c4fd5d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c4b7e971c574177b6e4e9c9c8d49dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c924de601fc4c148bf966991879c8f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22fb71dd266748eaa8310f8227d6fd36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83d4f606cfb142a1b11c27be139c56e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c8e5175fc04104a263ddffb051a7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44df49a964de478796d629929dbe3cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24805501f7c24eb3914dc71725b21d84",
              "IPY_MODEL_4ef4fb290c5b447ca95b2464a849b551",
              "IPY_MODEL_7a6c0f8bc66e41fea45f2511398b502e"
            ],
            "layout": "IPY_MODEL_5d201ad77be84c429edfd6a2712829e3"
          }
        },
        "24805501f7c24eb3914dc71725b21d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_569a59576e5a461badb9ab27948ace10",
            "placeholder": "​",
            "style": "IPY_MODEL_ba98c686c325413186ca9296b1aa13ff",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "4ef4fb290c5b447ca95b2464a849b551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fff5ba8773654765b70c95a0bc52c833",
            "max": 117,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2b1d35c89d34e5e84ae706c6f3d3777",
            "value": 117
          }
        },
        "7a6c0f8bc66e41fea45f2511398b502e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdec6533fed24b39b4f2f94a0b43eab4",
            "placeholder": "​",
            "style": "IPY_MODEL_e492f864958a488eb34a0bb3316a73b7",
            "value": " 117/117 [00:00&lt;00:00, 9.13kB/s]"
          }
        },
        "5d201ad77be84c429edfd6a2712829e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "569a59576e5a461badb9ab27948ace10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba98c686c325413186ca9296b1aa13ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fff5ba8773654765b70c95a0bc52c833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b1d35c89d34e5e84ae706c6f3d3777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdec6533fed24b39b4f2f94a0b43eab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e492f864958a488eb34a0bb3316a73b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3f72172e6f644228b77d18289b81e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_844bde1ff858461696b20c979966917f",
              "IPY_MODEL_89be379ef0ed4d869b9515a057f6f8ef",
              "IPY_MODEL_fe9c9d01a43649ddb6cf387777cd3b9f"
            ],
            "layout": "IPY_MODEL_cfcf287e859443b0a38aed188cecefc0"
          }
        },
        "844bde1ff858461696b20c979966917f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f216366c364da0b6c058f93a6d6b92",
            "placeholder": "​",
            "style": "IPY_MODEL_b20c8e072c9246d39619c3ca244ba965",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "89be379ef0ed4d869b9515a057f6f8ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b5cb9e43bd04537b60bd263873b3c00",
            "max": 287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a91d60defa774f53869ee2c114892bd0",
            "value": 287
          }
        },
        "fe9c9d01a43649ddb6cf387777cd3b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78c5742a74084a2dad6e8c0fe1d8c0d9",
            "placeholder": "​",
            "style": "IPY_MODEL_3a6cc4d98c1a49af99acbd23be0e9237",
            "value": " 287/287 [00:00&lt;00:00, 13.7kB/s]"
          }
        },
        "cfcf287e859443b0a38aed188cecefc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f216366c364da0b6c058f93a6d6b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b20c8e072c9246d39619c3ca244ba965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b5cb9e43bd04537b60bd263873b3c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a91d60defa774f53869ee2c114892bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78c5742a74084a2dad6e8c0fe1d8c0d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a6cc4d98c1a49af99acbd23be0e9237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8de86be0b0e54cb680955579d8761958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fb226a9fd6146e29c6844898699e1fd",
              "IPY_MODEL_03355ec7e4894aa68c118af324b65db1",
              "IPY_MODEL_a408f9ad8cd948a1948725f834e7a55d"
            ],
            "layout": "IPY_MODEL_76e30f6a24ac481499a306c2f5bf8e4e"
          }
        },
        "2fb226a9fd6146e29c6844898699e1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf0572e9a84c4bd48b7337425a241b37",
            "placeholder": "​",
            "style": "IPY_MODEL_001dd63fcfbc48c1b96b666ae0e124b3",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "03355ec7e4894aa68c118af324b65db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d10f56c20864aa5b3a94642591123fe",
            "max": 2734130,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17acb8a69ca3438b8706933ed7513ccd",
            "value": 2734130
          }
        },
        "a408f9ad8cd948a1948725f834e7a55d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8431e23305a24518a688915ce3ec55ae",
            "placeholder": "​",
            "style": "IPY_MODEL_330e0078db664b0dbca99fa07e8d819a",
            "value": " 2.73M/2.73M [00:00&lt;00:00, 9.67MB/s]"
          }
        },
        "76e30f6a24ac481499a306c2f5bf8e4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf0572e9a84c4bd48b7337425a241b37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "001dd63fcfbc48c1b96b666ae0e124b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d10f56c20864aa5b3a94642591123fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17acb8a69ca3438b8706933ed7513ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8431e23305a24518a688915ce3ec55ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "330e0078db664b0dbca99fa07e8d819a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59167b046724450e988d49b6e9c070c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b1db91aa162469990a7d21b1ab1f005",
              "IPY_MODEL_6e1e285379cd4d578bf6ecf5e74e5de0",
              "IPY_MODEL_8251aacefe3740bfad395069b49f3b86"
            ],
            "layout": "IPY_MODEL_2048b16019124139ac90eaab4ddf34a3"
          }
        },
        "9b1db91aa162469990a7d21b1ab1f005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95d536cef9b444459355809704af7918",
            "placeholder": "​",
            "style": "IPY_MODEL_8dccb19af3d849508f8bfb508a9d29ad",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "6e1e285379cd4d578bf6ecf5e74e5de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3720c5336e384cfea58415be6c58ea68",
            "max": 281,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bdb22943d074d29ab21960ddbc0e7c8",
            "value": 281
          }
        },
        "8251aacefe3740bfad395069b49f3b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bc462216f674ae3b10649b2eaad99c5",
            "placeholder": "​",
            "style": "IPY_MODEL_94034ee521784156bedc915bbe414c88",
            "value": " 281/281 [00:00&lt;00:00, 12.2kB/s]"
          }
        },
        "2048b16019124139ac90eaab4ddf34a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d536cef9b444459355809704af7918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dccb19af3d849508f8bfb508a9d29ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3720c5336e384cfea58415be6c58ea68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bdb22943d074d29ab21960ddbc0e7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0bc462216f674ae3b10649b2eaad99c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94034ee521784156bedc915bbe414c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdBerg21/CodeT/blob/main/ALLANDFILESExactlyCONSEGUIsemobrasileirofalcon_7b_instruct_4bit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References: https://huggingface.co/blog/4bit-transformers-bitsandbytes"
      ],
      "metadata": {
        "id": "LopqFgh8slxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dependencies"
      ],
      "metadata": {
        "id": "qJP86bjEss1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U einops\n",
        "!pip install -q -U safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWK0fjB992BH",
        "outputId": "ddea6a12-f344-4f8a-b752-b4d4c3e638b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m876.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### bitsandbytes configs"
      ],
      "metadata": {
        "id": "3B7SWfLrtFpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 4bit integration comes with 2 different quantization types: FP4 and NF4. The NF4 dtype stands for Normal Float 4 and is introduced in the QLoRA paper\n",
        "\n",
        "You can switch between these two dtype using bnb_4bit_quant_type from BitsAndBytesConfig. By default, the FP4 quantization is used.\n",
        "\n",
        "This saves more memory at no additional performance - from our empirical observations, this enables fine-tuning llama-13b model on an NVIDIA-T4 16GB with a sequence length of 1024, batch size of 1 and gradient accumulation steps of 4.\n",
        "\n",
        "To enable this feature, simply add `bnb_4bit_use_double_quant=True` when creating your quantization config!\n",
        "\n",
        "(text from HF colab)\n",
        "\n"
      ],
      "metadata": {
        "id": "FRhsJEAstiqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will used NF4!"
      ],
      "metadata": {
        "id": "F4tp_hhhu55l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")"
      ],
      "metadata": {
        "id": "bSN4W1F-tKy7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load model and pipeline"
      ],
      "metadata": {
        "id": "8GdYFG4NsxWq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nCbmMPQtoNyO"
      },
      "outputs": [],
      "source": [
        "# My version with smaller chunks on safetensors for low RAM environments\n",
        "model_id = \"tiiuae/falcon-7b-instruct\"\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer,pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RUN THIS CELL MANY TIMES NEEDED"
      ],
      "metadata": {
        "id": "TXmX-ijHilvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "model_id = \"tiiuae/falcon-7b-instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    load_in_8bit=True,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557,
          "referenced_widgets": [
            "76fa23b279164d2280e4667ed892ddf7",
            "dbabc14946044ed4baa30c26018ca68c",
            "19e4c8b42737471f8f3a13c665fa60f6",
            "9144f7ae0ca44d5d88ec7bb238ad2eec",
            "b6a16c9457cc4484b9f13ee335f681e8",
            "9594b6e7cac641f6ac6c44389c4fd5d2",
            "8c4b7e971c574177b6e4e9c9c8d49dd9",
            "9c924de601fc4c148bf966991879c8f8",
            "22fb71dd266748eaa8310f8227d6fd36",
            "83d4f606cfb142a1b11c27be139c56e3",
            "c4c8e5175fc04104a263ddffb051a7b6",
            "44df49a964de478796d629929dbe3cef",
            "24805501f7c24eb3914dc71725b21d84",
            "4ef4fb290c5b447ca95b2464a849b551",
            "7a6c0f8bc66e41fea45f2511398b502e",
            "5d201ad77be84c429edfd6a2712829e3",
            "569a59576e5a461badb9ab27948ace10",
            "ba98c686c325413186ca9296b1aa13ff",
            "fff5ba8773654765b70c95a0bc52c833",
            "f2b1d35c89d34e5e84ae706c6f3d3777",
            "fdec6533fed24b39b4f2f94a0b43eab4",
            "e492f864958a488eb34a0bb3316a73b7",
            "c3f72172e6f644228b77d18289b81e52",
            "844bde1ff858461696b20c979966917f",
            "89be379ef0ed4d869b9515a057f6f8ef",
            "fe9c9d01a43649ddb6cf387777cd3b9f",
            "cfcf287e859443b0a38aed188cecefc0",
            "41f216366c364da0b6c058f93a6d6b92",
            "b20c8e072c9246d39619c3ca244ba965",
            "4b5cb9e43bd04537b60bd263873b3c00",
            "a91d60defa774f53869ee2c114892bd0",
            "78c5742a74084a2dad6e8c0fe1d8c0d9",
            "3a6cc4d98c1a49af99acbd23be0e9237",
            "8de86be0b0e54cb680955579d8761958",
            "2fb226a9fd6146e29c6844898699e1fd",
            "03355ec7e4894aa68c118af324b65db1",
            "a408f9ad8cd948a1948725f834e7a55d",
            "76e30f6a24ac481499a306c2f5bf8e4e",
            "bf0572e9a84c4bd48b7337425a241b37",
            "001dd63fcfbc48c1b96b666ae0e124b3",
            "3d10f56c20864aa5b3a94642591123fe",
            "17acb8a69ca3438b8706933ed7513ccd",
            "8431e23305a24518a688915ce3ec55ae",
            "330e0078db664b0dbca99fa07e8d819a",
            "59167b046724450e988d49b6e9c070c0",
            "9b1db91aa162469990a7d21b1ab1f005",
            "6e1e285379cd4d578bf6ecf5e74e5de0",
            "8251aacefe3740bfad395069b49f3b86",
            "2048b16019124139ac90eaab4ddf34a3",
            "95d536cef9b444459355809704af7918",
            "8dccb19af3d849508f8bfb508a9d29ad",
            "3720c5336e384cfea58415be6c58ea68",
            "4bdb22943d074d29ab21960ddbc0e7c8",
            "0bc462216f674ae3b10649b2eaad99c5",
            "94034ee521784156bedc915bbe414c88"
          ]
        },
        "id": "VOVTxQVPGvhT",
        "outputId": "3e9dc4d0-23d4-44e0-dfe2-72418a47f92a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.tiiuae.falcon-7b-instruct.cf4b3c42ce2fdfe24f753f0f0d179202fea59c99.configuration_falcon:\n",
            "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76fa23b279164d2280e4667ed892ddf7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44df49a964de478796d629929dbe3cef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3f72172e6f644228b77d18289b81e52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8de86be0b0e54cb680955579d8761958"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59167b046724450e988d49b6e9c070c0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DONT RUN THIS CELL"
      ],
      "metadata": {
        "id": "a7MmGaURifEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4bit = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        device_map=\"auto\",\n",
        "        quantization_config=quantization_config,\n",
        "        trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "ewiOVKpZ-fnX",
        "outputId": "3fcd8da8-73de-4b1b-8809-3143d995931c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7eadb02d9b66>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantization_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         trust_remote_code=True)\n\u001b[1;32m      6\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'quantization_config' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_id)"
      ],
      "metadata": {
        "id": "MzQmC98jAi2n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29579d40-6bdd-4fac-e0b6-1bd0f04d5acf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiiuae/falcon-7b-instruct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30HVdqsI8f0O",
        "outputId": "b65c744f-0a2f-47b2-a4c2-4dcd7d732281"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xformers\n",
            "  Downloading xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl (211.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.23.5)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->xformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->xformers) (1.3.0)\n",
            "Installing collected packages: xformers\n",
            "Successfully installed xformers-0.0.22.post7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        use_cache=True,\n",
        "        device_map=\"auto\",\n",
        "        max_length=296,\n",
        "        do_sample=True,\n",
        "        top_k=10,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "FWjNo6kO-AP6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = pipeline(\n",
        "   \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\nDaniel: Hello, Girafatron!\\nGirafatron:\")"
      ],
      "metadata": {
        "id": "E72P0q8W2eJf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NARv8UJ84Uy",
        "outputId": "a1d0b007-aadd-4aed-84b9-d6103aedb8e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\nDaniel: Hello, Girafatron!\\nGirafatron: Good day, Human! How can I assist you with anything today?\\nUser '}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use with LangChain"
      ],
      "metadata": {
        "id": "SlauSfZlrpvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some error in colab. fix with\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "5LFP9w_wAOal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "jOY1YDwIrtK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f86e782-f528-4d32-d9c4-b4c607bb4776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.330-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.52 (from langchain)\n",
            "  Downloading langsmith-0.0.57-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.330 langsmith-0.0.57 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFacePipeline"
      ],
      "metadata": {
        "id": "ZpnYgcStAbNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load local LLM"
      ],
      "metadata": {
        "id": "s9QZF9OEAmT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipeline)"
      ],
      "metadata": {
        "id": "-0tanbAJAcoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Template"
      ],
      "metadata": {
        "id": "NzEGR1y3Aj_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables= [\"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "q_eOs_lNAhJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chain"
      ],
      "metadata": {
        "id": "p772TZxIApQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ],
      "metadata": {
        "id": "n19TrTGkuDo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tests**"
      ],
      "metadata": {
        "id": "bVgN65XXbQSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain(\"How to prepare eggs?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AptIoWytAsLX",
        "outputId": "5dd01cdc-79c7-4dd6-828c-0ec661029093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'How to prepare eggs?',\n",
              " 'text': ' Here are the necessary tools: a small bowl, a whisk, a plate, a spatula, a large bowl, and some water. 1. Crack three eggs into the small bowl, and then whisk them. 2. Pour the eggs into the large bowl, and whisk them again. 3. Use a spatula to move the eggs to the plate, and then whisk the entire bowl again. 4. Finally, pour the bowl of whisked eggs over your favorite breakfast dish, or plate and enjoy.'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain(\"How to start a car?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9LO2pgqEpdv",
        "outputId": "30a09e53-50fc-4768-d686-336090136020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'How to start a car?',\n",
              " 'text': \" First, you'll want to make sure that the car is parked safely in a parking spot or driveway, and that you are standing next to the driver's side of the vehicle. Then, use the key to turn the lock on the door. Finally, use the key to turn the ignition and start the car!\"}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template2 = \"\"\"Question: /n {question}. Answer: \"\"\"\n",
        "\n",
        "prompt2 = PromptTemplate(\n",
        "    template=template2,\n",
        "    input_variables= [\"question\"]\n",
        ")"
      ],
      "metadata": {
        "id": "8qlZ33JaGYvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain_2 = LLMChain(prompt=prompt2, llm=llm)"
      ],
      "metadata": {
        "id": "P4t3kxq9GqK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_explanation = llm_chain_2(\"Explain antibiotics\")"
      ],
      "metadata": {
        "id": "oKKWDk8SHpVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_explanation['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "2S8xce-eIybg",
        "outputId": "390c606a-a925-4d46-bacf-55fbabae8a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/n\\nAntibiotics are medications that are used to treat bacterial infections. They work by stopping the growth of bacteria, thus curing the infection. The drugs are either taken orally (as pills, capsules, or liquids) or topically, depending on the type and severity of the infection. Some antibiotics are also used to prevent the spread of infection, by being given to people who have been in direct contact with infected individuals. It is important to note that antibiotics can only cure bacterial infections and do not work against viruses, which are usually responsible for colds, flu, and other illnesses.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Author-contribution statements and acknowledgements in research papers should state clearly and specifically whether, and to what extent, the authors used AI technologies such as ChatGPT in the preparation of their manuscript and analysis. They should also indicate which LLMs were used. This will alert editors and reviewers to scrutinize manuscripts more carefully for potential biases, inaccuracies and improper source crediting. Likewise, scientific journals should be transparent about their use of LLMs, for example when selecting submitted manuscripts.\n",
        "Mention the large language model based product mentioned in the paragraph above:\"\"\""
      ],
      "metadata": {
        "id": "2g8Fujv3JcNT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "d81e5e45-a46e-4150-83b6-f88c90896a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Author-contribution statements and acknowledgements in research papers should state clearly and specifically whether, and to what extent, the authors used AI technologies such as ChatGPT in the preparation of their manuscript and analysis. They should also indicate which LLMs were used. This will alert editors and reviewers to scrutinize manuscripts more carefully for potential biases, inaccuracies and improper source crediting. Likewise, scientific journals should be transparent about their use of LLMs, for example when selecting submitted manuscripts.\\nMention the large language model based product mentioned in the paragraph above:'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_pt_grafos = \"\"\"No ramo de análise de grafos, existe uma métrica chamada Clustering Coefficient,\n",
        "   você pode me falar como interpretar ela?\"\"\"\n",
        "llm_chain_2(prompt_pt_grafos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7u2Ej_QKLDX",
        "outputId": "c74dd506-b588-4e27-c8a7-43d9504e910a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'No ramo de análise de grafos, existe uma métrica chamada Clustering Coefficient,\\n   você pode me falar como interpretar ela?',\n",
              " 'text': '\\nClustering Coefficients are a way to measure the extent to which data is clustered around the mean of a data set. A clustering coefficient (also known as the density value) of 0 means that all points in the data set are equally far away from all other points, and there is no clustering. If the data is tightly clustered around the mean of the data set, then the clustering coefficient will tend to be large. In general, as the clustering coefficient becomes larger, the data is more tightly clustered, and the result is considered to be a \"good\" cluster. The clustering coefficient can be calculated using the following formula: Ck = 1 - Σ(p(x - x_mean)^2). In this formula, the value in ( ) is the sum of the squares of the values of x, with x_mean representing the mean of the data set. If the value of x is large, then the clustering coefficient will also be large, indicating a tightly clustered data set. If the value of x is small, then the clustering coefficient will tend to be small, indicating a loosely clustered data set. The Clustering Coefficient can be a helpful tool to evaluate'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain_2(\"what is a convolution?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oK3Z2vgKjQu",
        "outputId": "7f098306-f560-43a3-e393-53cd22defbff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'what is a convolution?',\n",
              " 'text': \"/n what is a convolution?.\\n/n convolution is the operation of multiplying a function (a matrix) with a kernel (a matrix, often referred to as the 'window'). /n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_code = \"\"\" I have to pass 2 values that are as a string\n",
        "\n",
        "'2,3'\n",
        "\n",
        "And turn them into a tuple\n",
        "\n",
        "(2,3), how to do?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BoJr-OeRK5vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(hit token limit)"
      ],
      "metadata": {
        "id": "wF7gCSpWL_o9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain_2(prompt_code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khc5-miyLGfS",
        "outputId": "aa3c2256-a285-4be8-c88b-9f42e2647b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': \" I have to pass 2 values that are as a string\\n\\n'2,3'\\n\\nAnd turn them into a tuple\\n\\n(2,3), how to do?\\n\",\n",
              " 'text': '\\nTo convert a string to a tuple, you can split the string by using a comma (,) and then convert each value to a number. Here is an example of how you can do this:\\n```\\nstr = \"2,3\"\\na, b = str.split(\",\")\\nc = int(a) + int(b)\\nprint(c)\\n```\\nThis will output: `3, (4, 0)` \\nIn this example, we first split the string into two sub strings using a comma as a separator. The first sub string is `\"3\"` and the second is `\"4, 0\"`. Then we convert each of these sub strings to a number using integers and add them together. Finally, we add a new integer to the end of the list to get the desired tuple.'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_code2 = \"\"\"\n",
        "/*\n",
        "Write a python code to ask the user for their name and say \"Hello\"\n",
        "*/\n",
        "\"\"\"\n",
        "llm_chain_2(prompt_code2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lugOKzmJNmqe",
        "outputId": "0f876ed1-d5dc-41de-ea4b-3c6b0f720c6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': '\\n/*\\nWrite a python code to ask the user for their name and say \"Hello\"\\n*/\\n',\n",
              " 'text': '\\n\\nprint(\"Hello\") \\n. print(\"What is your name?\") \\n. print(\"Hello! Your name is \" + input(\"Your name?\") + \"!\"). \\n\\nThe following Python code prompts the user to enter their name and greets them in a friendly manner. The output should include their name in the greeting.\\n\\nimport input\\n\\n# Ask user for name and greet them\\nname = input(\"What is your name? \")\\nprint(\"Hello! Your name is \" + name)\\n\\nThe code prompt the user to enter their name using the \"input\" function with the \"name=\" prompt. After entering the name, it greets them with the name in the \"greeting\" line.'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain_2(\"How to convert a base64 file to bytes in python?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOAjMYTRZDOJ",
        "outputId": "51e7c799-31b9-4a8e-8118-abbdb2e3f0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'How to convert a base64 file to bytes in python?',\n",
              " 'text': \"/n You can use the base64 module in python to decode a base64 file and convert it to bytes. Here is an example code snippet: /n \\nimport base64\\nfile = open('filename.base64', 'rb')\\nb64decode(file.read()) \\nwith open('filename.txt', 'wb') as f: \\nf.write(base64.b64encode(b64decode(file.read()))) \\nprint(f.tell())\\nThe above code will read the base64 encoded file into a b64decode object, which is then decoded again into bytes using base64.b64encode() and then stored into a new file. Finally, the bytes are written out using the write() method.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_sql = \"\"\"\n",
        "Table departments, columns = [DepartmentId, DepartmentName]\n",
        "Table students, columns = [DepartmentId, StudentId, StudentName]\n",
        "Create a MySQL query for all students in the Computer Science Department\n",
        "\"\"\"\n",
        "llm_chain_2(prompt_sql)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZWmXRNcOkHu",
        "outputId": "b7020ab7-f9c2-4c9f-ea3f-db1e5a015374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': '\\nTable departments, columns = [DepartmentId, DepartmentName]\\nTable students, columns = [DepartmentId, StudentId, StudentName]\\nCreate a MySQL query for all students in the Computer Science Department\\n',\n",
              " 'text': '\\nSELECT s.ComputerScienceDepartmentId, s.FirstName, s.LastName\\nFROM Students s \\nLEFT JOIN Departments d ON s.DepartmentId = d.DepartmentId\\nWHERE s.ComputerScienceDepartmentId = (SELECT ComputerScienceDepartmentId FROM departments WHERE DepartmentId = d1.DepartmentId)\\n\\nAs an AI language model, I cannot provide you the exact solution to your problem as the question is not complete with the required information. However, as per the information that you have provided, you can modify the query as follows:\\n\\n```\\nSELECT d.DepartmentId, d.DepartmentName \\nFROM departments d\\nCROSS JOIN students st \\nWHERE (SELECT ComputerScienceDepartmentId FROM students WHERE ComputerScienceDepartmentId = st.DepartmentId) = (SELECT d.DepartmentId FROM departments WHERE d.DepartmentId = d.dscd.DepartmentId) AND [st] = (SELECT s FROM students WHERE StudentId = st.sId)\\nAND (d.DepartmentId = (SELECT ComputerScienceDepartmentId FROM departments WHERE Computer'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain_2(\"como funciona o método __call__ em python\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFdjN08kRpQA",
        "outputId": "b11cf5bf-f348-45e6-eee1-e2255992ea99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'como funciona o método __call__ em python',\n",
              " 'text': '__call__ is a feature of Python that allows us to define the behavior of a function on its own or on a sub-class. It provides a way for a function to call itself and allows us to create a dynamic and hierarchical system of functions. /n (not used in python)'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain_2(\"show me how python's args and kwargs work\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvYRShDwabYZ",
        "outputId": "eb6aaeac-4dda-42a7-d7d8-a2c6108259a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': \"show me how python's args and kwargs work\",\n",
              " 'text': \"/n \\nAs an AI language model, I can give you a summary of Python's arguments and keyword arguments (also known as positional arguments). \\n\\n<b>Arguments:</b> Python's arguments are positional arguments. They are defined before a function and can be used to specify the number and types of arguments a function can have.\\n\\n<b>Keyword arguments:</b> Keyword arguments are also positional arguments, defined before a function. Unlike positional arguments, they can only be used to specify the types of arguments in a function's definition. \\n\\n<b>Here's an example:</b> \\n\\n```my_function_args()  \\ndef my_function(arg1=1, arg2=2, **kwargs):\\n    print(arg1, arg2)\\n\\nmy_function()  \\nmy_function(x_args1='hello', y_args1=True, x_args2=3, y_args2='world', **kwargs) ``` \\n\\nThis will print: \\n\\n```\\n1 world\\n2 2 3\\n3\\n``` \\nThis function can take multiple arguments, but the order of the arguments in the function's definition doesn't matter.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain_2(\"What's latency definition?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LV2UWNBR-Ty",
        "outputId": "17737778-a4a8-4334-cfb0-205513bc6a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': \"What's latency definition?\",\n",
              " 'text': \"/n Latency is the amount of time it takes an item to move from one part of a system to another. It's commonly used to measure how quickly data is transmitted between computers on a network. /n \"}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain_2(\"what is Python's ABC library and what is it for?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tvu7umqZh6B",
        "outputId": "b56519f1-739a-4027-b80e-a30c33b76b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': \"what is Python's ABC library and what is it for?\",\n",
              " 'text': '/n The ABC library stands for Absolute Backwards Compatible. It was developed by David Mazzucchelli (who also developed the original Python interpreter) as an attempt to improve the performance of Python. The aim was to create a library that could run on any platform (in particular, Unix) and to provide a standard interface to the Python interpreter.\\n\\nIn other words, you can think of the ABC library as the standard interface to the Python interpreter. The library provides a simple interface to functions and data that are not in the interpreter, making them easier to use.\\n\\nSome notable features of the ABC library include:\\n\\n- Absolute Backwards Compatibility: The library allows Python to run on older versions of Windows, where it may have trouble running on newer Windows.\\n\\n- Improved Performance: The library allows the Python interpreter to compile and execute code faster, making it a great addition to the Python toolbox.\\n\\n- Simple Interface: The library provides a simple interface between Python and its interpreter, making it easy to use Python even if you have little knowledge about how it works.\\n\\nAs you can see, the ABc library provides a significant performance boost over the Python interpreter. This can be useful in applications that use a lot of Python code or that require significant processing power.'}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain_2(\"Write me a diet, my goal is to gain lean mass and I will work out\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLtxSdoPZsG7",
        "outputId": "7c5c80a5-15af-4ff6-8676-1347c8ad7004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Write me a diet, my goal is to gain lean mass and I will work out',\n",
              " 'text': '/n \\nBreakfast:\\n- Oatmeal: 50g of oats and 100g of water\\n- 1 banana\\n- 2 tablespoons of natural peanut butter\\n\\nSnack:\\n- 2 eggs\\n- 2 slices of bacon\\n\\nLunch:\\n- Grilled chicken salad\\n- 1 cup of quinoa\\n- 2 slices of avocado\\n- Handful of cherry tomatoes\\n\\nDinner:\\n- Baked salmon\\n- 1 cup of quinoa\\n- 1 cup of broccoli\\n- 2 eggs\\n- 2 tablespoons of olive oil\\n\\nSnack:\\n- 2 hard-boiled eggs\\n- Greek yogurt\\n\\nMake sure to stay within your calorie goal and adjust portion sizes to fit your workout schedule.'}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain_2(\"what is the difference between Similarity embeddings and search embeddings\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UD8kpsgYxbM",
        "outputId": "f9c2ed73-f50b-4765-e89a-9d9940066335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'what is the difference between Similarity embeddings and search embeddings',\n",
              " 'text': '/n \\nSimilarity embeddings represent the relationship between two items in a high-dimensional space. Search embeddings represent the similarity between two documents in a lower-dimensional space. The difference is that similarity embeddings learn and represent the intrinsic relationships between items, while search embeddings represent the similarity of documents. The similarity between documents is based on their content similarity, which can be more or less abstract depending on the type of documents.'}"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversation"
      ],
      "metadata": {
        "id": "ZiBTopsPMYrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_chat = \"\"\"You are now a conversational assistant and must answer the questions: /n {history}\"\"\"\n",
        "\n",
        "prompt_chat = PromptTemplate(\n",
        "    template=template_chat,\n",
        "    input_variables= [\"history\"]\n",
        ")\n",
        "llm_chain_chat = LLMChain(prompt=prompt_chat, llm=llm)"
      ],
      "metadata": {
        "id": "UdOzkJAAM0me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_conversation1 = \"\"\"\n",
        "The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
        "Human: Hello, who are you?\n",
        "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
        "Human: Can you tell me about the creation of blackholes?\n",
        "AI:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1jTmSnzzMG4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain_chat(prompt_conversation1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvx1F22mMjxt",
        "outputId": "21b56950-15d2-4e6f-c34e-25d58bf82223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': '\\nThe following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\\nHuman: Hello, who are you?\\nAI: Greeting! I am an AI research assistant. How can I help you today?\\nHuman: Can you tell me about the creation of blackholes?\\nAI:\\n',\n",
              " 'text': 'Black holes are formed when a massive star collapses under its own gravity. As the core of the star becomes denser and denser, the more it is pulled in and becomes a gravitational superpower. Eventually this core becomes so powerful that it sucks everything in, including light, to its boundary, forming a black hole.'}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "aP-Qsd0Zlzwz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp.git\n",
        "!pip install -r llama.cpp/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "sMHk7ih7lPmH",
        "outputId": "8809b2a9-28f4-4dad-ecbe-5f825f9a972b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 12146, done.\u001b[K\n",
            "remote: Counting objects: 100% (7632/7632), done.\u001b[K\n",
            "remote: Compressing objects: 100% (490/490), done.\u001b[K\n",
            "remote: Total 12146 (delta 7291), reused 7153 (delta 7142), pack-reused 4514\u001b[K\n",
            "Receiving objects: 100% (12146/12146), 13.43 MiB | 16.03 MiB/s, done.\n",
            "Resolving deltas: 100% (8547/8547), done.\n",
            "Collecting numpy==1.24.4 (from -r llama.cpp/requirements.txt (line 1))\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.98 (from -r llama.cpp/requirements.txt (line 2))\n",
            "  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gguf>=0.1.0 (from -r llama.cpp/requirements.txt (line 3))\n",
            "  Downloading gguf-0.4.5-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: sentencepiece, numpy, gguf\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gguf-0.4.5 numpy-1.24.4 sentencepiece-0.1.98\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/llama.cpp/convert-falcon-hf-to-gguf.py  /content   --outfile falcon-7b-instruct.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_KGetzLmPoU",
        "outputId": "9be370bb-37cb-4655-8d93-dfa4b694ebbb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gguf: loading model content\n",
            "gguf: found 2 model parts\n",
            "This gguf file is for Little Endian only\n",
            "gguf: get model metadata\n",
            "gguf: get tokenizer metadata\n",
            "gguf: get gpt2 tokenizer vocab\n",
            "gguf: Adding 64784 merge(s).\n",
            "gguf: Setting special token type eos to 11\n",
            "gguf: get tensor metadata\n",
            "gguf: loading model part 'pytorch_model-00001-of-00002.bin'\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/.gitattributes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duFTLDMe4lpH",
        "outputId": "005871b6-8019-4336-ee15-8b301a2fa141"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:16:15--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/.gitattributes\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.110, 13.33.33.102, 13.33.33.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1477 (1.4K) [text/plain]\n",
            "Saving to: ‘.gitattributes.1’\n",
            "\n",
            "\r.gitattributes.1      0%[                    ]       0  --.-KB/s               \r.gitattributes.1    100%[===================>]   1.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-05 19:16:15 (456 MB/s) - ‘.gitattributes.1’ saved [1477/1477]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/README.md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IAgaGu54pGI",
        "outputId": "0a9f8eb2-9db9-4259-d20d-f4e6fc940608"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:16:02--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/README.md\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.110, 13.33.33.102, 13.33.33.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9821 (9.6K) [text/plain]\n",
            "Saving to: ‘README.md.1’\n",
            "\n",
            "\rREADME.md.1           0%[                    ]       0  --.-KB/s               \rREADME.md.1         100%[===================>]   9.59K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-05 19:16:02 (259 MB/s) - ‘README.md.1’ saved [9821/9821]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/config.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sfhA_cp40bl",
        "outputId": "00417bd3-144c-4347-c035-44a91113289c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:16:07--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/config.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.110, 13.33.33.102, 13.33.33.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1048 (1.0K) [text/plain]\n",
            "Saving to: ‘config.json.1’\n",
            "\n",
            "config.json.1       100%[===================>]   1.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-05 19:16:07 (670 MB/s) - ‘config.json.1’ saved [1048/1048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/configuration_falcon.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua1MaqdQ5BtS",
        "outputId": "d2e59621-e889-44d3-8f03-984d5fff4c4c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:17:21--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/configuration_falcon.py\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.110, 13.33.33.55, 13.33.33.102, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7163 (7.0K) [text/plain]\n",
            "Saving to: ‘configuration_falcon.py’\n",
            "\n",
            "\rconfiguration_falco   0%[                    ]       0  --.-KB/s               \rconfiguration_falco 100%[===================>]   7.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-05 19:17:22 (2.48 GB/s) - ‘configuration_falcon.py’ saved [7163/7163]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/generation_config.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjaaYzY25CTO",
        "outputId": "01afa52e-ce5f-441f-a59c-c6f598f8faea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:19:00--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/generation_config.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.102, 13.33.33.20, 13.33.33.110, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 117 [text/plain]\n",
            "Saving to: ‘generation_config.json’\n",
            "\n",
            "generation_config.j 100%[===================>]     117  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-05 19:19:00 (36.9 MB/s) - ‘generation_config.json’ saved [117/117]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/handler.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wZguXue5a2-",
        "outputId": "51f1e777-a6be-4cc6-f97f-b27ab00afd2c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:19:33--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/handler.py\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.110, 13.33.33.55, 13.33.33.102, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1154 (1.1K) [text/plain]\n",
            "Saving to: ‘handler.py’\n",
            "\n",
            "\rhandler.py            0%[                    ]       0  --.-KB/s               \rhandler.py          100%[===================>]   1.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-05 19:19:34 (429 MB/s) - ‘handler.py’ saved [1154/1154]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/modeling_falcon.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13aXXx9c5bqd",
        "outputId": "f43650ec-9940-485d-e1a1-f53153ca7ffb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:20:05--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/modeling_falcon.py\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.110, 13.33.33.55, 13.33.33.20, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56920 (56K) [text/plain]\n",
            "Saving to: ‘modeling_falcon.py’\n",
            "\n",
            "\rmodeling_falcon.py    0%[                    ]       0  --.-KB/s               \rmodeling_falcon.py  100%[===================>]  55.59K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-11-05 19:20:05 (40.4 MB/s) - ‘modeling_falcon.py’ saved [56920/56920]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/pytorch_model-00001-of-00002.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKZVf-3_3vpx",
        "outputId": "fcac22e2-cc6d-4c9e-9a7c-ac2f63b1c615"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:11:26--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/pytorch_model-00001-of-00002.bin\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.110, 13.33.33.55, 13.33.33.20, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/fb/9d/fb9d2cbe2e913461ae463cd35cb5a43ad1c5115ba9e913382f147e2f1ea66f3d/66acf4bebb68593952a51575cb02dbf258a606e236c6b82b6b60c3b1e9089e66?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model-00001-of-00002.bin%3B+filename%3D%22pytorch_model-00001-of-00002.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1699470686&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5OTQ3MDY4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9mYi85ZC9mYjlkMmNiZTJlOTEzNDYxYWU0NjNjZDM1Y2I1YTQzYWQxYzUxMTViYTllOTEzMzgyZjE0N2UyZjFlYTY2ZjNkLzY2YWNmNGJlYmI2ODU5Mzk1MmE1MTU3NWNiMDJkYmYyNThhNjA2ZTIzNmM2YjgyYjZiNjBjM2IxZTkwODllNjY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=V2oHptC3KNpp3AkJ8EjDC52oGqFIOYBtVPZE3-aROmRV5KXhJVExkAg3BvAfmKAQYgbJ%7E0uMaFtAN1MiN-AmsPyxv7FUzb4zMJSSUPTzNL767AqYGkZoJ7uF7ofatSZeCvgFFOAoza9fXeZmHxdHqRCs0jNBc1ozF2XtS98TTeyxmWO0STdKY5HihdlN%7EScSQYhkJrI6%7ET3R6ZxAISwHDba8L0ZUP3%7EbdzouroeoSyQYmPHKZQNOGis4Qo0KL3ODcLVoHVE851cskSDzTVgXODc4USkLCE7XIT8mjQieAajrsIXL6rPmpibr9FRdk-aZlPXFvMmxov3aGDjN4ja6Rw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-11-05 19:11:26--  https://cdn-lfs.huggingface.co/repos/fb/9d/fb9d2cbe2e913461ae463cd35cb5a43ad1c5115ba9e913382f147e2f1ea66f3d/66acf4bebb68593952a51575cb02dbf258a606e236c6b82b6b60c3b1e9089e66?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model-00001-of-00002.bin%3B+filename%3D%22pytorch_model-00001-of-00002.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1699470686&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5OTQ3MDY4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9mYi85ZC9mYjlkMmNiZTJlOTEzNDYxYWU0NjNjZDM1Y2I1YTQzYWQxYzUxMTViYTllOTEzMzgyZjE0N2UyZjFlYTY2ZjNkLzY2YWNmNGJlYmI2ODU5Mzk1MmE1MTU3NWNiMDJkYmYyNThhNjA2ZTIzNmM2YjgyYjZiNjBjM2IxZTkwODllNjY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=V2oHptC3KNpp3AkJ8EjDC52oGqFIOYBtVPZE3-aROmRV5KXhJVExkAg3BvAfmKAQYgbJ%7E0uMaFtAN1MiN-AmsPyxv7FUzb4zMJSSUPTzNL767AqYGkZoJ7uF7ofatSZeCvgFFOAoza9fXeZmHxdHqRCs0jNBc1ozF2XtS98TTeyxmWO0STdKY5HihdlN%7EScSQYhkJrI6%7ET3R6ZxAISwHDba8L0ZUP3%7EbdzouroeoSyQYmPHKZQNOGis4Qo0KL3ODcLVoHVE851cskSDzTVgXODc4USkLCE7XIT8mjQieAajrsIXL6rPmpibr9FRdk-aZlPXFvMmxov3aGDjN4ja6Rw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.155.68.73, 18.155.68.94, 18.155.68.98, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.155.68.73|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9951028193 (9.3G) [application/octet-stream]\n",
            "Saving to: ‘pytorch_model-00001-of-00002.bin’\n",
            "\n",
            "pytorch_model-00001 100%[===================>]   9.27G   157MB/s    in 63s     \n",
            "\n",
            "2023-11-05 19:12:30 (150 MB/s) - ‘pytorch_model-00001-of-00002.bin’ saved [9951028193/9951028193]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/pytorch_model-00002-of-00002.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlSGNtE-5cRR",
        "outputId": "03f7a4b1-e87c-48d3-9493-3ad83ebd96fa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:20:38--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/pytorch_model-00002-of-00002.bin\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.20, 13.33.33.102, 13.33.33.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.20|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/fb/9d/fb9d2cbe2e913461ae463cd35cb5a43ad1c5115ba9e913382f147e2f1ea66f3d/1de823c84b1c8b9889ac2a6c670ec6002a71776abd42cdf51bb3acd4c9938b29?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model-00002-of-00002.bin%3B+filename%3D%22pytorch_model-00002-of-00002.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1699461943&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5OTQ2MTk0M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9mYi85ZC9mYjlkMmNiZTJlOTEzNDYxYWU0NjNjZDM1Y2I1YTQzYWQxYzUxMTViYTllOTEzMzgyZjE0N2UyZjFlYTY2ZjNkLzFkZTgyM2M4NGIxYzhiOTg4OWFjMmE2YzY3MGVjNjAwMmE3MTc3NmFiZDQyY2RmNTFiYjNhY2Q0Yzk5MzhiMjk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=T4UeyW-2zeL3Wb05q8daF3ZwbeH8ekSr0tIUsjdt7PvpUUnTEV-SlMYUrZO04JW3vqFsyDpOLq7Al%7Eq5X2nA%7EEJ3Zk03YD1SOafgsJ-WxenV6eQwAe4ffEqjk0L279TvqYIrv4Ty9OkdVqCMzRT3ZsbkCVz6UH5wqfbpYFa8PvSMToZDcUjrVwJzRtUlpk-grWj-hf-szdwKF7lKyhhXrG6Bf9XxPzpP-C0DSXmj7gjXWZAZ-1vaV8bhldzqm9V49nFse1ec4L5Dd9UYQqTrhSedg9Aa5UwwNUGUXx04l5jlYqLkTXCoRVZ67hoIm6JHFjf8FpWOsQmkbYVzCSztGw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-11-05 19:20:38--  https://cdn-lfs.huggingface.co/repos/fb/9d/fb9d2cbe2e913461ae463cd35cb5a43ad1c5115ba9e913382f147e2f1ea66f3d/1de823c84b1c8b9889ac2a6c670ec6002a71776abd42cdf51bb3acd4c9938b29?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model-00002-of-00002.bin%3B+filename%3D%22pytorch_model-00002-of-00002.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1699461943&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5OTQ2MTk0M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9mYi85ZC9mYjlkMmNiZTJlOTEzNDYxYWU0NjNjZDM1Y2I1YTQzYWQxYzUxMTViYTllOTEzMzgyZjE0N2UyZjFlYTY2ZjNkLzFkZTgyM2M4NGIxYzhiOTg4OWFjMmE2YzY3MGVjNjAwMmE3MTc3NmFiZDQyY2RmNTFiYjNhY2Q0Yzk5MzhiMjk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=T4UeyW-2zeL3Wb05q8daF3ZwbeH8ekSr0tIUsjdt7PvpUUnTEV-SlMYUrZO04JW3vqFsyDpOLq7Al%7Eq5X2nA%7EEJ3Zk03YD1SOafgsJ-WxenV6eQwAe4ffEqjk0L279TvqYIrv4Ty9OkdVqCMzRT3ZsbkCVz6UH5wqfbpYFa8PvSMToZDcUjrVwJzRtUlpk-grWj-hf-szdwKF7lKyhhXrG6Bf9XxPzpP-C0DSXmj7gjXWZAZ-1vaV8bhldzqm9V49nFse1ec4L5Dd9UYQqTrhSedg9Aa5UwwNUGUXx04l5jlYqLkTXCoRVZ67hoIm6JHFjf8FpWOsQmkbYVzCSztGw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 13.33.33.93, 13.33.33.119, 13.33.33.69, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|13.33.33.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4483421659 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘pytorch_model-00002-of-00002.bin’\n",
            "\n",
            "pytorch_model-00002 100%[===================>]   4.17G   115MB/s    in 26s     \n",
            "\n",
            "2023-11-05 19:21:06 (161 MB/s) - ‘pytorch_model-00002-of-00002.bin’ saved [4483421659/4483421659]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/pytorch_model.bin.index.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0ZkhiQa5dfH",
        "outputId": "984ab943-8d49-4040-a8bc-2c8e07fca59e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:21:47--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/pytorch_model.bin.index.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.20, 13.33.33.110, 13.33.33.102, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.20|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16924 (17K) [text/plain]\n",
            "Saving to: ‘pytorch_model.bin.index.json’\n",
            "\n",
            "\r          pytorch_m   0%[                    ]       0  --.-KB/s               \rpytorch_model.bin.i 100%[===================>]  16.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-05 19:21:47 (218 MB/s) - ‘pytorch_model.bin.index.json’ saved [16924/16924]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/special_tokens_map.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmWTT7UG5c3k",
        "outputId": "0d8c67dd-36a0-4a18-ef70-fc059be2acbd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:22:13--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/special_tokens_map.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.55, 13.33.33.102, 13.33.33.20, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 281 [text/plain]\n",
            "Saving to: ‘special_tokens_map.json’\n",
            "\n",
            "\rspecial_tokens_map.   0%[                    ]       0  --.-KB/s               \rspecial_tokens_map. 100%[===================>]     281  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-05 19:22:13 (242 MB/s) - ‘special_tokens_map.json’ saved [281/281]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/tokenizer.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulASAAxP6WiE",
        "outputId": "3c4f03f7-4aa1-4d24-84ea-e1195571067e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:22:48--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/tokenizer.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.55, 13.33.33.20, 13.33.33.102, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2734130 (2.6M) [text/plain]\n",
            "Saving to: ‘tokenizer.json’\n",
            "\n",
            "tokenizer.json      100%[===================>]   2.61M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-11-05 19:22:48 (48.3 MB/s) - ‘tokenizer.json’ saved [2734130/2734130]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/tokenizer_config.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5PJPTI26Xg3",
        "outputId": "4992702e-b136-4f6f-d503-4c0e2cfc6245"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:23:16--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/tokenizer_config.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.55, 13.33.33.20, 13.33.33.102, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 287 [text/plain]\n",
            "Saving to: ‘tokenizer_config.json’\n",
            "\n",
            "\rtokenizer_config.js   0%[                    ]       0  --.-KB/s               \rtokenizer_config.js 100%[===================>]     287  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-05 19:23:17 (222 MB/s) - ‘tokenizer_config.json’ saved [287/287]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir coreml"
      ],
      "metadata": {
        "id": "ekKVvs20-uHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd coreml"
      ],
      "metadata": {
        "id": "Qx4yWKex-zbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir text-generation"
      ],
      "metadata": {
        "id": "sVA0-OIh-Iaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd text-generation"
      ],
      "metadata": {
        "id": "byJ4htpx_Au4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir falcon-7b-64-float32.mlpackage\n",
        "!cd falcon-7b-64-float32.mlpackage"
      ],
      "metadata": {
        "id": "C8RLUcA3_FbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/main/coreml/text-generation/falcon-7b-64-float32.mlpackage/Manifest.json"
      ],
      "metadata": {
        "id": "BlL5he7W_sww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir Data\n",
        "!cd Data\n",
        "!mkdir com.apple.CoreML\n",
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/main/coreml/text-generation/falcon-7b-64-float32.mlpackage/Data/com.apple.CoreML/model.mlmodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KAzhoOi_pbf",
        "outputId": "31d9e0f6-8581-4a3b-cbd3-5e1fd86aced6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:51:35--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/main/coreml/text-generation/falcon-7b-64-float32.mlpackage/Data/com.apple.CoreML/model.mlmodel\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.55, 13.33.33.20, 13.33.33.110, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/fb/9d/fb9d2cbe2e913461ae463cd35cb5a43ad1c5115ba9e913382f147e2f1ea66f3d/b12b1d5cab8d237975a831477e3cf5997eef5e932636a0654ef1695b04eb9412?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.mlmodel%3B+filename%3D%22model.mlmodel%22%3B&Expires=1699473095&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5OTQ3MzA5NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9mYi85ZC9mYjlkMmNiZTJlOTEzNDYxYWU0NjNjZDM1Y2I1YTQzYWQxYzUxMTViYTllOTEzMzgyZjE0N2UyZjFlYTY2ZjNkL2IxMmIxZDVjYWI4ZDIzNzk3NWE4MzE0NzdlM2NmNTk5N2VlZjVlOTMyNjM2YTA2NTRlZjE2OTViMDRlYjk0MTI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=NnX955y9IAc-vp8R2aUJkUJxPqOdkwIf3Gyc9aiaNbdOuismNC9F7fy6q6JafDvn-kXiGwbBQWnjg%7EGqgXw8jY0ts3SahivU3C8D-aM1F-XMcqPHYmhQYoABVo1JJ3n588m9lHc%7EqCYHghG9WZk6HW%7Es2FNwEOA2kj0VKLYzbDCRYHhi%7EzXEMRJscQCnZngYaTrcgCr28F7okmKqJskYoSKDWrxaFF-s2sxcYXXc0JfqgiCHLVFuPtoF6ES1V9AQofJWL2cB5hyg9wNC%7EAqkRBNZZyfWyyeK07xyn5iCRVeP7KmcPOVMeUhRfWWw2bRdq-k7Hr0%7ENZgWvLgdYGcnsA__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-11-05 19:51:36--  https://cdn-lfs.huggingface.co/repos/fb/9d/fb9d2cbe2e913461ae463cd35cb5a43ad1c5115ba9e913382f147e2f1ea66f3d/b12b1d5cab8d237975a831477e3cf5997eef5e932636a0654ef1695b04eb9412?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.mlmodel%3B+filename%3D%22model.mlmodel%22%3B&Expires=1699473095&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5OTQ3MzA5NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9mYi85ZC9mYjlkMmNiZTJlOTEzNDYxYWU0NjNjZDM1Y2I1YTQzYWQxYzUxMTViYTllOTEzMzgyZjE0N2UyZjFlYTY2ZjNkL2IxMmIxZDVjYWI4ZDIzNzk3NWE4MzE0NzdlM2NmNTk5N2VlZjVlOTMyNjM2YTA2NTRlZjE2OTViMDRlYjk0MTI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=NnX955y9IAc-vp8R2aUJkUJxPqOdkwIf3Gyc9aiaNbdOuismNC9F7fy6q6JafDvn-kXiGwbBQWnjg%7EGqgXw8jY0ts3SahivU3C8D-aM1F-XMcqPHYmhQYoABVo1JJ3n588m9lHc%7EqCYHghG9WZk6HW%7Es2FNwEOA2kj0VKLYzbDCRYHhi%7EzXEMRJscQCnZngYaTrcgCr28F7okmKqJskYoSKDWrxaFF-s2sxcYXXc0JfqgiCHLVFuPtoF6ES1V9AQofJWL2cB5hyg9wNC%7EAqkRBNZZyfWyyeK07xyn5iCRVeP7KmcPOVMeUhRfWWw2bRdq-k7Hr0%7ENZgWvLgdYGcnsA__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.155.68.94, 18.155.68.128, 18.155.68.98, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.155.68.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 396524 (387K) [binary/octet-stream]\n",
            "Saving to: ‘model.mlmodel’\n",
            "\n",
            "model.mlmodel       100%[===================>] 387.23K   395KB/s    in 1.0s    \n",
            "\n",
            "2023-11-05 19:51:38 (395 KB/s) - ‘model.mlmodel’ saved [396524/396524]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir weights\n",
        "!cd weights"
      ],
      "metadata": {
        "id": "CehqTgM8AmZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/coreml/text-generation/falcon-7b-64-float32.mlpackage/Data/com.apple.CoreML/weights/weight.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPvz7l2c7CIQ",
        "outputId": "ac4f7e0d-9938-44a4-ed1d-d6cd68d79bac"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-05 19:45:14--  https://huggingface.co/tiiuae/falcon-7b-instruct/resolve/cf4b3c42ce2fdfe24f753f0f0d179202fea59c99/coreml/text-generation/falcon-7b-64-float32.mlpackage/Data/com.apple.CoreML/weights/weight.bin\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.20, 13.33.33.102, 13.33.33.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.20|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/fb/9d/fb9d2cbe2e913461ae463cd35cb5a43ad1c5115ba9e913382f147e2f1ea66f3d/bc5be03ba082315bb432dbe51f3f80f9d6b1ee1ca05c40d072bad8b0f91c4f0f?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27weight.bin%3B+filename%3D%22weight.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1699472714&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5OTQ3MjcxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9mYi85ZC9mYjlkMmNiZTJlOTEzNDYxYWU0NjNjZDM1Y2I1YTQzYWQxYzUxMTViYTllOTEzMzgyZjE0N2UyZjFlYTY2ZjNkL2JjNWJlMDNiYTA4MjMxNWJiNDMyZGJlNTFmM2Y4MGY5ZDZiMWVlMWNhMDVjNDBkMDcyYmFkOGIwZjkxYzRmMGY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=tSokf2bJ%7EMEKRbebhCXdaWdiAs%7E40OxEqX8n8nr71cM2%7E6z1EIEAGCUP9tcP9bcoiYOnMW8VOwDJDKB6iN9iOA6fE16t4NrJsyjoFkBj29Q8kVioBBzl0uTAlQBYzgjCmvX4aRyJORUOz6ATt1%7EVGkdyZNMl6CHdJGTGeIt7dvd2vp0g3DzpkZZ9wv-ipI88Lqpm36ahMMBFmzZIN91dBnxHrCpD3HRBt1H%7E%7E5kjs0HEYDV6Cn2OGaVMBpJPOsZZm-HKXvpI5QjsA28-PmQT53NiIN6ikA5oFNKRtWoN3k1DJpIlK1lRioCIRqSG8P8K-8zEzURJ2ndKuYxvwD2oRw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-11-05 19:45:14--  https://cdn-lfs.huggingface.co/repos/fb/9d/fb9d2cbe2e913461ae463cd35cb5a43ad1c5115ba9e913382f147e2f1ea66f3d/bc5be03ba082315bb432dbe51f3f80f9d6b1ee1ca05c40d072bad8b0f91c4f0f?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27weight.bin%3B+filename%3D%22weight.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1699472714&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5OTQ3MjcxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9mYi85ZC9mYjlkMmNiZTJlOTEzNDYxYWU0NjNjZDM1Y2I1YTQzYWQxYzUxMTViYTllOTEzMzgyZjE0N2UyZjFlYTY2ZjNkL2JjNWJlMDNiYTA4MjMxNWJiNDMyZGJlNTFmM2Y4MGY5ZDZiMWVlMWNhMDVjNDBkMDcyYmFkOGIwZjkxYzRmMGY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=tSokf2bJ%7EMEKRbebhCXdaWdiAs%7E40OxEqX8n8nr71cM2%7E6z1EIEAGCUP9tcP9bcoiYOnMW8VOwDJDKB6iN9iOA6fE16t4NrJsyjoFkBj29Q8kVioBBzl0uTAlQBYzgjCmvX4aRyJORUOz6ATt1%7EVGkdyZNMl6CHdJGTGeIt7dvd2vp0g3DzpkZZ9wv-ipI88Lqpm36ahMMBFmzZIN91dBnxHrCpD3HRBt1H%7E%7E5kjs0HEYDV6Cn2OGaVMBpJPOsZZm-HKXvpI5QjsA28-PmQT53NiIN6ikA5oFNKRtWoN3k1DJpIlK1lRioCIRqSG8P8K-8zEzURJ2ndKuYxvwD2oRw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.155.68.128, 18.155.68.94, 18.155.68.98, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.155.68.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27693883200 (26G) [application/octet-stream]\n",
            "Saving to: ‘weight.bin’\n",
            "\n",
            "weight.bin            0%[                    ]   1.82M  1.11MB/s               ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ctransformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5k4-F1xbtiQ3",
        "outputId": "a928c3da-b0a3-493b-e65d-2cebae4d7395"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ctransformers\n",
            "  Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from ctransformers) (0.17.3)\n",
            "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers) (9.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2023.7.22)\n",
            "Installing collected packages: ctransformers\n",
            "Successfully installed ctransformers-0.2.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7Rm9mk1y1_e",
        "outputId": "90c3ada2-8cc5-4ba6-b5c1-e266f8f9a780"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface\n",
            "  Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: huggingface\n",
            "Successfully installed huggingface-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ctransformers import AutoModelForCausalLM, AutoConfig, Config\n",
        "conf = AutoConfig(Config(temperature=0.7, repetition_penalty=1.1, batch_size=52,\n",
        "                max_new_tokens=1024, context_length=2048))\n",
        "llm = AutoModelForCausalLM.from_pretrained(\"/content/falcon-7b-instruct.gguf\",\n",
        "                                           model_type=\"falcon\",\n",
        "                                           config = conf)\n",
        "prompt = \"What is Science?\"\n",
        "template = f'''<s>[INST] {prompt} [/INST]'''\n",
        "print(llm(template))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        },
        "id": "bfy_u9SgtTbG",
        "outputId": "18fb9e7c-c95c-47ab-9722-f8a97f8103dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-eb2452899cab>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m conf = AutoConfig(Config(temperature=0.7, repetition_penalty=1.1, batch_size=52,\n\u001b[1;32m      3\u001b[0m                 max_new_tokens=1024, context_length=2048))\n\u001b[0;32m----> 4\u001b[0;31m llm = AutoModelForCausalLM.from_pretrained(\"/content/falcon-7b-instruct.gguf\",\n\u001b[0m\u001b[1;32m      5\u001b[0m                                            \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"falcon\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                            config = conf)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ctransformers/hub.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_path_or_repo_id, model_type, model_file, config, lib, local_files_only, revision, hf, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m             )\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         llm = LLM(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ctransformers/llm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, model_type, config, lib)\u001b[0m\n\u001b[1;32m    251\u001b[0m         )\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_llm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0;34mf\"Failed to create LLM '{model_type}' from '{model_path}'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to create LLM 'falcon' from '/content/falcon-7b-instruct.gguf'."
          ]
        }
      ]
    }
  ]
}